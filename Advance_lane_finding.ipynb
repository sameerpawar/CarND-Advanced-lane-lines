{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell we perform one time task of Caliberation: mtx, dist\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "CALIBRATE = False\n",
    "PERSPECTIVE = False\n",
    "DISPLAY = True\n",
    "\n",
    "# Load calibration and perspective\n",
    "npzfile = np.load('calibration_n_perspective.npz')\n",
    "mtx  = npzfile['mtx']\n",
    "dist = npzfile['dist']\n",
    "M    = npzfile['M']\n",
    "\n",
    "if CALIBRATE:\n",
    "    nx = 9\n",
    "    ny = 6\n",
    "    objp = np.zeros((nx*ny,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob( './camera_cal/calibration*.jpg')\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, \n",
    "                                                           (img.shape[1], img.shape[0]), None,None)\n",
    "    \n",
    "if DISPLAY:\n",
    "    img = cv2.imread('./camera_cal/calibration20.jpg')\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    plt.imshow(undist)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell we perform one time task of getting perspective transform matrix: M\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "'''\n",
    "not so good\n",
    "pt1 = [603, 446]\n",
    "pt2 = [676, 446]\n",
    "pt3 = [1042, 678]\n",
    "pt4 = [265, 678]\n",
    "'''\n",
    "\n",
    "'''\n",
    "better than before this\n",
    "pt1 = [575, 465]\n",
    "pt2 = [708, 465]\n",
    "pt3 = [1040, 678]\n",
    "pt4 = [265, 678]\n",
    "\n",
    "'''\n",
    "\n",
    "pt1 = [540, 490]\n",
    "pt2 = [748, 490]\n",
    "pt3 = [1040, 678]\n",
    "pt4 = [265, 678]\n",
    "\n",
    "src = np.float32([pt1, pt2, pt3, pt4])\n",
    "\n",
    "pt1 = [300, 0]\n",
    "pt2 = [1010, 0]\n",
    "pt3 = [1010, 720]\n",
    "pt4 = [300, 720]\n",
    "dst = np.float32([pt1, pt2, pt3, pt4])\n",
    "\n",
    "if PERSPECTIVE:\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "if DISPLAY:\n",
    "    img = mpimg.imread('./test_images/straight_lines1.jpg')\n",
    "    fname = './test_images/straight_lines1_Warped.jpg'\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    warped = cv2.warpPerspective(undist, M, img_size)\n",
    "    mpimg.imsave(fname, warped, format='jpg')\n",
    "    plt.imshow(warped)\n",
    "    plt.show()\n",
    "\n",
    "    img = mpimg.imread('./test_images/straight_lines2.jpg')\n",
    "    fname = './test_images/straight_lines2_Warped.jpg'\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    warped = cv2.warpPerspective(undist, M, img_size)\n",
    "    mpimg.imsave(fname, warped, format='jpg')\n",
    "    plt.imshow(warped)\n",
    "    plt.show()\n",
    "    print(img.shape)\n",
    "\n",
    "#np.savez('calibration_n_perspective', mtx = mtx, dist = dist, M = M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DISPLAY:\n",
    "    img = mpimg.imread('./test_images/test6.jpg')\n",
    "    fname = './test_images/test2_Warped.jpg'\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    warped = cv2.warpPerspective(undist, M, img_size)\n",
    "    mpimg.imsave(fname, warped, format='jpg')\n",
    "    plt.imshow(warped)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def abs_sobel_thresh(image, orient='x', sobel_kernel=3, thresh=(0, 255), nchannels = 1):\n",
    "    # Convert to grayscale if the image is color\n",
    "    if nchannels == 3:\n",
    "        image   = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize = sobel_kernel)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize = sobel_kernel)\n",
    "    \n",
    "    abs_sobel       = np.absolute(sobel)    \n",
    "    scaled_sobel    = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    \n",
    "    grad_binary     = np.zeros_like(scaled_sobel)\n",
    "    grad_binary[(thresh[0] <= scaled_sobel) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return grad_binary\n",
    "\n",
    "def mag_thresh(image, sobel_kernel=3, mag_thresh=(0, 255), nchannels = 1):\n",
    "    # Convert to grayscale if the image is color\n",
    "    if nchannels == 3:\n",
    "        image   = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize = sobel_kernel)\n",
    "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize = sobel_kernel)\n",
    "    \n",
    "    abs_sobel       = np.sqrt(np.square(sobelx) + np.square(sobely))    \n",
    "    scaled_sobel    = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    \n",
    "    mag_binary  = np.zeros_like(scaled_sobel)\n",
    "    mag_binary[(mag_thresh[0] <= scaled_sobel) & (scaled_sobel <= mag_thresh[1])] = 1\n",
    "    return mag_binary\n",
    "\n",
    "def dir_threshold(image, sobel_kernel=3, thresh=(0, np.pi/2), nchannels = 1):\n",
    "    # Convert to grayscale if the image is color\n",
    "    if nchannels == 3:\n",
    "        image   = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    abs_sobelx = np.absolute(cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize = sobel_kernel))\n",
    "    abs_sobely = np.absolute(cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize = sobel_kernel))\n",
    "    \n",
    "    grad_direction  = np.arctan2(abs_sobely, abs_sobelx)  \n",
    "    dir_binary      = np.zeros_like(grad_direction)\n",
    "    dir_binary[(thresh[0] <= grad_direction) & (grad_direction <= thresh[1])] = 1\n",
    "    return dir_binary\n",
    "\n",
    "\n",
    "def hls_select(img, thresh=(0, 255), channel = 's'):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    if channel == 'h':\n",
    "        C = hls[:,:,0]\n",
    "    if channel == 'l':    \n",
    "        C = hls[:,:,1]\n",
    "    if channel == 's':\n",
    "        C = hls[:,:,2]\n",
    "\n",
    "    C = np.absolute(C).astype(float)\n",
    "    C = np.uint8(255*C/np.max(C))\n",
    "    binary_output = np.zeros_like(C) \n",
    "    binary_output[(thresh[0] < C) & (C <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def rgb_select(img, thresh=(0, 255), channel = 'r'):\n",
    "    if channel == 'r':\n",
    "        C = img[:,:,0]\n",
    "    if channel == 'g':    \n",
    "        C = img[:,:,1]\n",
    "    if channel == 'b':\n",
    "        C = img[:,:,2]\n",
    "\n",
    "    C = np.absolute(C).astype(float)\n",
    "    C = np.uint8(255*C/np.max(C))\n",
    "    binary_output = np.zeros_like(C) \n",
    "    binary_output[(thresh[0] < C) & (C <= thresh[1])] = 1\n",
    "    return binary_output    \n",
    "\n",
    "# Edit this function to create your own pipeline.\n",
    "'''Pipeline:\n",
    "1. undistort the image using mtx, dist\n",
    "1. Apply combination threshold to get a binary image with potential lane line pixels.\n",
    "1. Apply perspective transformation to get the bird eye view.\n",
    "'''\n",
    "\n",
    "def pipeline(img, ksize = 3):\n",
    "    image = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    gradx = abs_sobel_thresh(image, orient='x', sobel_kernel=ksize, thresh=(10, 100), nchannels = 3)\n",
    "    grady = abs_sobel_thresh(image, orient='y', sobel_kernel=ksize, thresh=(30, 100), nchannels = 3)\n",
    "    mag_binary = mag_thresh(image, sobel_kernel=ksize, mag_thresh=(30, 255), nchannels = 3)\n",
    "    dir_binary = dir_threshold(image, sobel_kernel=ksize, thresh=(0, 1.4), nchannels = 3)\n",
    "    s_binary = hls_select(image, thresh=(40, 255), channel = 's')\n",
    "    h_binary = hls_select(image, thresh=(15, 100), channel = 'h')\n",
    "    r_binary = rgb_select(image, thresh=(150, 255), channel = 'r')\n",
    "    \n",
    "\n",
    "    # Combine various binaries \n",
    "    combined_binary = np.zeros_like(image[:,:,0])\n",
    "    combined_binary[gradx == 1] = 1\n",
    "    combined_binary[grady == 1] = 1\n",
    "    combined_binary[h_binary == 1] = 1\n",
    "    combined_binary[r_binary == 1] = 1\n",
    "    combined_binary[s_binary == 1] = 1\n",
    "    combined_binary[mag_binary == 0] = 0\n",
    "    combined_binary[dir_binary == 0] = 0\n",
    "    \n",
    "    binary_image = cv2.warpPerspective(combined_binary, M, (img.shape[1], img.shape[0]), flags=cv2.INTER_NEAREST)  # keep same size as input image    \n",
    "    return binary_image   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of calibration images\n",
    "images = glob.glob( './test_images/test1*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    # Read in an image and grayscale it\n",
    "    image   = mpimg.imread(fname)\n",
    "    # top_down, perspective_M = corners_unwarp(img, nx, ny, mtx, dist)\n",
    "    combined_binary = pipeline(image, ksize = 3)\n",
    "\n",
    "    #plt.imshow(combined_binary)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(combined_binary, cmap='gray')\n",
    "    ax2.set_title('Combined Thresholded', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
